---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: https://github.com/hannahyu07/US-Election"
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(here)
library(rstanarm)
library(modelsummary)
library(ggplot2)
library(knitr)
library(marginaleffects)
```


# Introduction

You can and should cross-reference sections and sub-sections. We use @citeR and @rohan.

The remainder of this paper is structured as follows. @sec-data....

## Estimand



# Data {#sec-data}



## Data Measurement



## Summary Statistics



Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}
# read in data
ces2020 <-  read_csv(here::here("data/analysis_data/cleaned_ces2020.csv"))
```

```{r}
# change column type to factor
ces2020 <-
  ces2020 |>
  mutate(
    voted_for = as_factor(voted_for),
    race = factor(
      race,
      levels = c(
        "White",
        "Black",
        "Hispanic",
        "Asian",
        "Native American",
        "Middle Eastern",
        "Two or more races",
        "Other"
      )
    ),
    region = factor(
      region,
      levels = c(
        "Northeast",
        "Midwest",
        "South",
        "West"
      )
    ),
    employ = factor(
      employ,
      levels = c(
        "Full-time",
        "Part-time",
        "Temporarily laid off",
        "Unemployed",
        "Retired",
        "Permanently disabled",
        "Homemaker",
        "Student",
        "Other"
      )
    )
  ) |>
  select(voted_for, race, region, employ)
```


# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in 

[Appendix -@sec-model-details].

## Model set-up

In our analysis, we utilized a Bayesian logistic regression model to examine the relationship between voter preferences and various demographic and socioeconomic factors. The model is formulated as follows:

\begin{align} 
y_i|\pi_i &\sim \mbox{Bern}(\pi_i) \\
\mbox{logit}(\pi_i) &= \alpha + \beta_1 \times \mbox{race}_i + \beta_2 \times \mbox{region}_i + \beta_3 \times \mbox{employ}_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5)
\end{align}

In this model, $y_i$ represents the binary outcome variable indicating whether an individual voted for a particular candidate (e.g., Biden or Trump). The probability of voting for the candidate ($\pi_i$) is modeled using a logistic link function (\text{logit}($\pi_i$)), which is a linear combination of the intercept ($\alpha$) and the coefficients ($\beta_1$, $\beta_2$, $\beta_3$)) corresponding to the predictor variables race, region, and employment status, respectively. These predictor variables are denoted as \text{race}_i, \text{region}_i, and \text{employ}_i, where $i$ indexes the individuals in the dataset.

The intercept ($\alpha$) and coefficients ($\beta_1$, $\beta_2$, $\beta_3$) are assigned informative prior distributions to regularize the model. Specifically, we assume a normal distribution with a mean of 0 and a standard deviation of 2.5 for each parameter.

We chose this modeling approach for several reasons. Firstly, logistic regression is well-suited for binary outcome variables, making it appropriate for analyzing voting behavior. Additionally, Bayesian methods allow us to incorporate prior knowledge and uncertainty into our analysis, providing more robust estimates of the model parameters.

Alternative modeling approaches, such as machine learning algorithms, were also considered. However, we chose Bayesian logistic regression for its flexibility, interpretability, and ability to handle uncertainty.


We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

To avoid exessive runtime, we randomly sampled 1000 observations to fit the model. 

### Model justification

We expect a positive relationship between individuals of Black, Asian, and Hispanic ethnicities and support for Biden. This expectation arises from Trump's history of spreading polarizing language and anti-immigrant sentiments, as well as his controversial plans such as building a border wall. These groups are more likely to align with Biden's policies, which prioritize inclusivity and diversity. White individuals with traditional family values and conservative leanings tend to support Trump. They are drawn to his emphasis on preserving traditional values and promises to uphold conservative principles, especially regarding immigration, law and order, and gun rights.

Conversely, we anticipate a negative relationship between voters in the South and Midwest regions and support for Biden. These regions have a stronger conservative presence and a history of supporting Republican candidates like Trump. States such as Texas and Florida, which are known Republican strongholds, are located in the South. Therefore, individuals in these regions may be less inclined to support Biden's progressive agenda.

Regarding employment status, we expect students, unemployed individuals, and those temporarily laid off to be more inclined to support Biden. Students are often exposed to diverse perspectives and progressive ideas in educational settings, making them more likely to endorse Biden's platform. Unemployed and laid-off individuals may favor Biden due to the Democratic Party's advocacy for social welfare programs and support for workers' rights.

The voting behavior of employed individuals is harder to distinguish. Some working individuals support Trump due to their opposition to higher taxes and prefer his promises of tax cuts and economic deregulation. Conversely, others lean towards Biden because they believe tax increases should primarily target the wealthy and not burden the middle class.
Additionally, educated and liberal-leaning working professionals may prioritize issues such as healthcare, climate change, and social justice, aligning them with Biden's platform. 


-------------------------------needs some explanation
```{r}
# We could use posterior predictive checks, introduced in Section 12.4, to show that the logistic regression approach is a good choice for this circumstance.

pp_check(political_preferences1) +
  theme(legend.position = "bottom")
```


# Results
```{r}
#| label: fig-race_region
#| fig-cap: The distribution of presidential preferences, by region and race
#| echo: false

ces2020 |>
  ggplot(aes(x = race, fill = voted_for)) +
  stat_count(position = "dodge") +
  facet_wrap(facets = vars(region)) +
  theme_minimal() +
  labs(
    x = "Race",
    y = "Number of respondents",
    fill = "Voted for"
  ) +
  coord_flip() +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "bottom")
```
```{r}
#| label: fig-race_employ
#| fig-cap: The distribution of presidential preferences, by region and employment status
#| echo: false

ces2020 |>
  ggplot(aes(x = employ, fill = voted_for)) +
  stat_count(position = "dodge") +
  facet_wrap(facets = vars(region)) +
  theme_minimal() +
  labs(
    x = "Employment status",
    y = "Number of respondents",
    fill = "Voted for"
  ) +
  coord_flip() +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "bottom")
```
```{r}
#| label: fig-race_employ_white
#| fig-cap: The distribution of presidential preferences, by region and employment status, only white people
#| echo: false

ces2020_selected_data <- ces2020[ces2020$race == "White", ]

ces2020_selected_data |>
  ggplot(aes(x = employ, fill = voted_for)) +
  stat_count(position = "dodge") +
  facet_wrap(facets = vars(region)) +
  theme_minimal() +
  labs(
    x = "Employment status",
    y = "Number of respondents",
    fill = "Voted for"
  ) +
  coord_flip() +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "bottom")
```

```{r stateplot, echo=F, message=F, warning=F, fig.cap="Proportion of each State Voting for Biden"}
# get state by state proportions for our polling data
polling_props <- polling %>% 
  group_by(stateicp, vote_biden) %>% 
  summarise(n = n()) %>% 
  mutate(prop = n/sum(n)) 

# combine the polling data proportions with the post-stratification data
poll_post_biden <- inner_join(polling_props, voting_biden, by = "stateicp")
poll_post_biden <- poll_post_biden %>% 
  filter(vote_biden == 1)

# plot for predictions

poll_post_biden %>% 
  ggplot(aes(x = stateicp, y = biden_predict)) +
  geom_point(aes(color = "black")) +
  geom_line(aes(group = 1)) +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 70, size = 6, hjust = 1)) +
  geom_ribbon(aes(group = 1, ymin=biden_predict_lower, ymax=biden_predict_upper), 
              alpha = 0.2, fill = "red") +
  geom_line(data = poll_post_biden, aes(x=stateicp, y=prop, group = 2), 
            linetype = "twodash") +
  geom_point(data = poll_post_biden, aes(x=stateicp, y=prop, colour = "red")) +
  geom_hline(aes(yintercept = 0.5), alpha = 0.5) +
  scale_color_discrete(name = "Data", labels = c("Population", "Sample")) +
  labs(title = "Proportion of People voting for Joe Biden by State",
       x = "State", y = "Percentage Voting Biden")
```




Our results are summarized in @tbl-modelresults.


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: tbl-modelresults1
#| tbl-cap: "Explanatory models Political Preferences (n = 1000)"

political_preferences1 <-
  readRDS(file = here::here("models/political_preferences1.rds"))

# Change variable names directly in the model object
names(political_preferences1$coefficients) <- c(
  "Intercept", "Black", "Hispanic", "Middle Eastern", "Native American", 
  "Other race", "Two or more races", "White", "Northeast", "South", "West",
  "Homemaker", "Other employment", "Part-time", "Permanently disabled", 
  "Retired", "Student", "Temporarily laid off", "Unemployed"
)


modelsummary(
  list(
    "Support Biden" = political_preferences1
  ),
  statistic = "mad"
  )
```
# need to be fixed
Our results generally matches our justification. To avoid multicollinearity, the model excluded three variables from each category: race Asian, region Midwest, and employed full-time.

The intercept represents the estimated log-odds of supporting Biden when all other predictors are held constant at their reference levels. In this case, the estimated log-odds of supporting Biden for individuals who are Asian, live in the Midwest, and are employed full-time is 0.806. 

Black people's support for Biden is large. The estimated coefficient of 2.549 means that, holding all other variables constant, Black individuals are estimated to have a 2.549 unit increase in the log-odds of supporting Biden compared to the reference group.

Hispanic races on average are also more likely to vote for Biden. (not significant)
We observe an outlier race other which has a 37.999 higher log-odds of supporting Biden compared to the reference group. 


```{r}

# Define the updated variable names
new_coef_names <- c(
  "Intercept", "Black", "Hispanic", "Middle Eastern", "Native American", 
  "Other race", "Two or more races", "White", "Northeast", "South", "West",
  "Homemaker", "Other employment", "Part-time", "Permanently disabled", 
  "Retired", "Student", "Temporarily laid off", "Unemployed"
)

# Update variable names in the model object
names(political_preferences1$coefficients) <- new_coef_names

# Print the updated model summary
print(
  modelsummary(
    list("Support Biden" = political_preferences1),
    statistic = "mad"
  )
)


```





```{r}
# Extract posterior samples
# posterior_samples <- as.matrix(political_preferences)
# 
# # Calculate credible intervals (e.g., 95%)
# credible_intervals <- apply(posterior_samples, 2, function(x) quantile(x, c(0.025, 0.975)))
# 
# # Extract coefficient names
# coefficient_names <- colnames(posterior_samples)
# 
# # Create a data frame with coefficient names, coefficient estimates, and credible intervals
# table_data <- data.frame(
#   Posterior_Mean = colMeans(posterior_samples),
#   Credible_Interval_Lower = credible_intervals[1, ],
#   Credible_Interval_Upper = credible_intervals[2, ]
# )
# 
# # Print the table
# print(table_data)


```
Due to the fact that the credibility interval for race Other is particularly large, we cannot observe the trend of the 90% credibility intervals of other variables. That's why we created a second plot with the x axis limited from -10 to 10. 


```{r}
modelplot(political_preferences1, conf_level = 0.9) +
  labs(x = "90 per cent credibility interval")
```

```{r}
# Create the model plot
model_plot <- modelplot(political_preferences1, conf_level = 0.9)

# Modify the x-axis limits
model_plot + xlim(-10, 10) +  # Adjust the limits as needed
  labs(x = "90% Credibility Interval")

```



# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]
# 
# pp_check(first_model) +
#   theme_classic() +
#   theme(legend.position = "bottom")
# 
# posterior_vs_prior(first_model) +
#   theme_minimal() +
#   scale_color_brewer(palette = "Set1") +
#   theme(legend.position = "bottom") +
#   coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

# plot(first_model, "trace")
# 
# plot(first_model, "rhat")
```



\newpage


# References


